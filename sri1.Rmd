---
title: "Data Analysis on Iris Flowers"
author: "Sridhar"
date: "7 January 2018"
output: 
  html_document:
    keep_md: true
---

## Load the data

```{r iris}
iris
```

## Scatterplot

By using scatterplots,we can find how much the parameters are correlated

```{r pressure, echo=FALSE}
library('ggvis')
iris %>% ggvis(~Sepal.Length,~Sepal.Width,fill =~Species) %>% layer_points()
```

The Sepal Length and Sepal width are some what correlated but not that much,we can see that the setosa,
is completely separated since they have small sepal length and small sepal width than other species.But 
the real problem is that the virgincia,versicolor species were mixed apart.Hence we move to the next parameters.

```{r}
iris %>% ggvis(~Petal.Length,~Petal.Width,fill = ~Species) %>% layer_points()
```
Check this,this scatterplot is pretty good,which separates the species and forms a perfect correlation
line.

## Correlations
Let's check the numerical correlations of the parameters
```{r}
print(cor(iris$Sepal.Length,iris$Sepal.Width))
print(cor(iris$Petal.Length,iris$Petal.Width))

```
## Correlation matrix

For each property the correlations are identified for different species i.e, sentosa,versicolor,virginica
```{r}
type <- levels(iris$Species)
print(type[1])
cor(iris[iris$Species==type[1],1:4])

print(type[2])
cor(iris[iris$Species==type[3],1:4])

print(type[3])
cor(iris[iris$Species==type[3],1:4])
```
## Knowing the data

```{r}
head(iris)
```
## Structure of the data

```{r}
str(iris)
```
## Tabulations

```{r}
table(iris$Species)
```

```{r}
round(prop.table(table(iris$Species)) * 100, digits = 1)

```

```{r}
summary(iris)
summary(iris[c("Petal.Width","Sepal.Width")])
```
## Normalization

The normalization/feature scaling is not necessary but still,it improves the accuracy of this classification system.Here normalization process makes all the columns to be in the range of 0 to 1.

```{r}
library(class)
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}


iris_norm <- as.data.frame(lapply(iris[1:4], normalize))


summary(iris_norm)
```
## Training and Testing sets

The dataset is divided into two parts
1) Training set : To train the classifier,it contains 2/3 of the dataset.
2) Testing set : To test the classifier,it contains 1/3 of the dataset.

So for the division purpose we need random rows,that's why we are using seed() method.
```{r}
set.seed(1234)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.67, 0.33))
ind
```

```{r}
iris.training <- iris[ind==1, 1:4]

head(iris.training)

iris.test <- iris[ind==2, 1:4]

head(iris.test)
```
Here the data is being separated!with the above found random possibilities.
```{r}
iris.trainLabels <- iris[ind==1,5]

print(iris.trainLabels)

iris.testLabels <- iris[ind==2, 5]

print(iris.testLabels)
```

## Classification

Here the k-Nearest Neighbour Classification is applied,with the training set and the testing set and the 
species were predicted.The knn() method does a good job by predicting the species based on the training 
set and they were tested by the testing set.

```{r}
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k=3)
iris_pred
```

## Comparison
 We need to make sure that our classifier has classified the species correctly,in order to do that we merge the real species name and the predicted name.As a result we find something unsual.

```{r}
irisTestLabels <- data.frame(iris.testLabels)

merge <- data.frame(iris_pred, iris.testLabels)

names(merge) <- c("Predicted Species", "Observed Species")

merge
```
The classifier did a small mistake i.e, instead of versicolor,it predicted as virginica.
This k-NN classification is not 100 % percent accurate.

## Proper summary

```{r}
library(gmodels)
CrossTable(x = iris.testLabels, y = iris_pred, prop.chisq=FALSE)
```
